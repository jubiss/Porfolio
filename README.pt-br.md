# Portfólio
[![en](https://img.shields.io/badge/lang-en-red.svg)](https://github.com/jubiss/Porfolio/blob/main/README.md)

Olá! Meu nome é José, mas você também pode me chamar de Zé ou Jubi. Bem-vindo ao meu Portfólio.

Aqui você encontrará o link para os repositórios dos meus projetos, juntamente com breves descrições de cada projeto, principais descobertas ou resultados. 
Se você deseja obter informações mais detalhadas, pode encontrá-las nos repositórios ou me enviar uma mensagem.

Por favor, observe que estou atualizando alguns dos meus projetos antigos, então você pode encontrar mudanças de tempos em tempos.

Você pode baixar meu currículo aqui: [inserir link para o currículo]

Se você tiver alguma dúvida ou quiser entrar em contato, sinta-se à vontade para me enviar um e-mail em jose.edivaldo.fisica@gmail.com ou se conectar comigo no LinkedIn: https://www.linkedin.com/in/joseferreiradata/.

Obrigado por visitar meu portfólio, espero que você encontre algo interessante nos projetos!

**E-mail**: jose.edivaldo.fisica@gmail.com

**LinkedIn**: https://www.linkedin.com/in/joseferreiradata/



# [Projeto: Scraper de Sites Imobiliários (Scrapy-Selenium)](https://github.com/jubiss/real_estate_crawler)  


Repositório: [GitHub - Real Estate Crawler](https://github.com/jubiss/real_estate_crawler)

Descrição:
Desenvolvi um **scraper estruturado** utilizando o framework **Scrapy-Selenium** para coletar dados imobiliários do site VivaReal, com enfoque na cidade de Recife. O projeto enfrentou desafios relacionados à manipulação de dados dinâmicos, uma vez que os sites imobiliários frequentemente atualizam suas informações. Além disso, implementei boas práticas, como a inclusão de um **lag entre as requisições** para evitar sobrecarregar os servidores e garantir a conformidade com as políticas dos sites.

Principais Características:
- Coleta estruturada de dados imobiliários em Recife.
- Utilização do framework Scrapy-Selenium para a interação com sites dinâmicos.
- Implementação de lag entre as requisições para evitar sobrecarga dos servidores.
- Manipulação e armazenamento organizados dos dados utilizando **pipelines e items** no Scrapy.

Este projeto demonstra minha habilidade em lidar com desafios de dados dinâmicos durante o scraping e aplicar boas práticas, como a inclusão de um lag adequado entre as requisições. A estruturação do projeto com pipelines e items no Scrapy garante a qualidade e organização dos dados coletados, permitindo análises futuras no mercado imobiliário.

No repositório [Real Estate Crawler](https://github.com/jubiss/real_estate_crawler), você pode encontrar mais detalhes sobre a implementação, código-fonte e configuração do projeto.
